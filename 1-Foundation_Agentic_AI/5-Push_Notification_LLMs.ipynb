{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6d03b4",
   "metadata": {},
   "source": [
    "# Intelligent Agents: Function Execution and Alerts with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0be7f",
   "metadata": {},
   "source": [
    "## Introducing Pushover\n",
    "Setting up Pushover for notifications is quick and hassle-free! Just follow these simple steps:\n",
    "\n",
    "### Create a Free Account\n",
    "Head over to https://pushover.net and sign up.\n",
    "\n",
    "#### Generate Your Tokens\n",
    "You‚Äôll need two tokens to enable notifications:\n",
    "\n",
    "#### üîë User Token ‚Äì Found on your Pushover dashboard.\n",
    "\n",
    "#### üõ†Ô∏è Application Token ‚Äì Create one by visiting https://pushover.net/apps/build and registering a new app.\n",
    "(This allows you to organize notifications into separate apps later.)\n",
    "\n",
    "#### Add to Your .env File\n",
    "Store your credentials securely by adding the following to your .env:\n",
    "\n",
    "PUSHOVER_USER=your_user_token_here\n",
    "\n",
    "PUSHOVER_TOKEN=your_app_token_here\n",
    "\n",
    "#### Install the Mobile App\n",
    "Download the Pushover app on your phone (iOS/Android) to start receiving real-time push notifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1dde0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c247143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Notification sent!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the Mobile Notifications\n",
    "PUSH_NOTIFICATION_URI=\"https://api.pushover.net/1/messages.json\"\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "\n",
    "def push_notification(message: str):\n",
    "    data={\n",
    "            \"token\": pushover_token,\n",
    "            \"user\": pushover_user,\n",
    "            \"message\": message\n",
    "        }\n",
    "    \n",
    "    response = requests.post(PUSH_NOTIFICATION_URI, data)\n",
    "    if response.status_code == 200:\n",
    "        return \"Notification sent!\"\n",
    "    else:\n",
    "        return f\"Failed to send: {response.text}\"\n",
    "\n",
    "push_notification(\"Test Mobile Notification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c045b7",
   "metadata": {},
   "source": [
    "These are variables are tool/function definitions in OpenAI‚Äôs function calling format. They describe to the language model what tools are available, what each tool does, and what parameters it needs.\n",
    "\n",
    "This allows the model to:\n",
    "\n",
    "Understand when to call a function.\n",
    "\n",
    "Know how to call it correctly, with validated arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11d83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Tools Functions\n",
    "\n",
    "def record_user_details(email, name=\"Name not provided\", notes=\"not provided\"):\n",
    "    push_notification(f\"[User Interest] {name} ({email}) | Notes: {notes}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "def record_unknown_question(question):\n",
    "    push_notification(f\"[Unknown Question] {question}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "# ---- Tool Schemas ----\n",
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Record a user's interest using their email and optional details.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\"type\": \"string\", \"description\": \"User's email address\"},\n",
    "            \"name\": {\"type\": \"string\", \"description\": \"User's name\"},\n",
    "            \"notes\": {\"type\": \"string\", \"description\": \"Additional context or comments\"},\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Log a question that the assistant couldn't answer.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"string\", \"description\": \"The unanswerable question\"},\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b6278",
   "metadata": {},
   "source": [
    "### Tool Dispatcher\n",
    "\n",
    "Receives tool calls from the LLM (usually via OpenAI‚Äôs function-calling feature)\n",
    "\n",
    "Executes the correct Python function\n",
    "\n",
    "Returns the result in a format the model expect\n",
    "\n",
    "You can think of it like a function router for the model's requests:\n",
    "\n",
    "‚ÄúThe model says: ‚ÄòCall record_user_details with this info.‚Äô\n",
    "\n",
    "Your code says: ‚ÄòGot it! Let me run that Python function and return the result.‚Äô‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf425e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Tool Dispatcher ----\n",
    "\n",
    "def handle_tool_calls(tool_calls):\n",
    "    \"\"\"Execute tool calls and return their results.\"\"\"\n",
    "    results= []\n",
    "\n",
    "    for call in tool_calls:\n",
    "        name = call.function.name\n",
    "        args = json.loads(call.function.arguments)\n",
    "\n",
    "        print(f\"Tool called: {name}\")\n",
    "        if name == \"record_user_details\":\n",
    "            result = record_user_details(**args)\n",
    "        elif name == \"record_unknown_question\":\n",
    "            result = record_unknown_question(**args)\n",
    "        else:\n",
    "            result = {\"error\": f\"Unknown tool: {name}\"}\n",
    "    \n",
    "    results.append({\n",
    "         \"role\": \"tool\",\n",
    "         \"content\": json.dumps(result),\n",
    "         \"tool_call_id\": call.id,\n",
    "    })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7225a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recorded': 'ok'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[\"record_user_details\"](\"jane@gmail.com.\")\n",
    "#print(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab2c183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Improved Tools Dispatcher ----\n",
    "\n",
    "# Tool function registry\n",
    "TOOL_FUNCTIONS = {\n",
    "    \"record_user_details\": record_user_details,\n",
    "    \"record_unknown_question\": record_unknown_question,\n",
    "}\n",
    "\n",
    "def dispatch_tool_calls(tool_calls):\n",
    "    \"\"\"Execute tool calls and return their results.\"\"\"\n",
    "    results= []\n",
    "\n",
    "    for call in tool_calls:\n",
    "        name = call.function.name\n",
    "        args = json.loads(call.function.arguments)\n",
    "        print(f\"Tool called: {name}\")\n",
    "\n",
    "        func = TOOL_FUNCTIONS.get(name)\n",
    "        if func:\n",
    "            try:\n",
    "                result = func(**args)\n",
    "            except Exception as e:\n",
    "                result = {\"error\": f\"Execution failed: {str(e)}\"}\n",
    "        else:\n",
    "            result = {\"error\": f\"Unknown tool: {name}\"}\n",
    "    \n",
    "    results.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps(result),\n",
    "        \"name\": name,\n",
    "        \"tool_call_id\": call.id,\n",
    "    })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f4ae42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Positive Test Case ---\n",
      "Tool called: record_user_details\n",
      "Tool called: record_unknown_question\n",
      "[{'role': 'tool', 'content': '{\"recorded\": \"ok\"}', 'name': 'record_unknown_question', 'tool_call_id': 'test-id'}]\n",
      "\n",
      "--- Negative Test Case ---\n",
      "Tool called: non_existent_tool\n",
      "Tool called: record_user_details\n",
      "[{'role': 'tool', 'content': '{\"error\": \"Execution failed: record_user_details() missing 1 required positional argument: \\'email\\'\"}', 'name': 'record_user_details', 'tool_call_id': 'test-id'}]\n"
     ]
    }
   ],
   "source": [
    "# Test dispatch_tool_calls function\n",
    "from types import SimpleNamespace\n",
    "import json\n",
    "\n",
    "# --- Mock Tool Call Class (similar to OpenAI's tool_call format) ---\n",
    "def make_tool_call(name, arguments, call_id=\"test-id\"):\n",
    "    return SimpleNamespace(\n",
    "        function=SimpleNamespace(name=name, arguments=json.dumps(arguments)),\n",
    "        id=call_id\n",
    "    )\n",
    "\n",
    "# --- Positive Test Case ---\n",
    "tool_calls_positive =[\n",
    "    make_tool_call(\"record_user_details\", {\"email\": \"anshulc55@icloud.com\", \"name\": \"Anshul Chauhan\"}),\n",
    "    make_tool_call(\"record_unknown_question\", {\"question\": \"What is the meaning of life?\"}),\n",
    "]\n",
    "\n",
    "# --- Negative Test Case ---\n",
    "tool_calls_negative = [\n",
    "    make_tool_call(\"non_existent_tool\", {\"Dummy\": \"Test Dummy Value\"}),\n",
    "    make_tool_call(\"record_user_details\", {})  # missing required \"email\"\n",
    "]\n",
    "\n",
    "# --- Run Tests ---\n",
    "print(\"\\n--- Positive Test Case ---\")\n",
    "print(dispatch_tool_calls(tool_calls_positive))\n",
    "\n",
    "print(\"\\n--- Negative Test Case ---\")\n",
    "print(dispatch_tool_calls(tool_calls_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0df983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parag Agrawal leads a balanced life that blends his demanding career with a strong emphasis on family and personal interests. He is married to Vineeta Agarwala, a general partner at the venture capital firm Andreessen Horowitz, where she invests in biotech and health tech. Together, they reside in San Francisco and are raising two children. Despite his high-profile career, Parag values quality time with his family and enjoys nurturing curiosity both personally and professionally. Outside of work, he has interests in reading, mentoring young talent, and staying connected with his cultural roots. His personal life reflects a grounded and thoughtful approach, complementing his innovative professional journey.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# Read the Profile PDF\n",
    "filePath = project_root / \"Resourses\" / \"Profile.pdf\"\n",
    "pdfReader = PdfReader(filePath)\n",
    "prof_summary = \"\"\n",
    "for page in pdfReader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        prof_summary += text\n",
    "\n",
    "# Read Summary file\n",
    "summ_filePath = project_root / \"Resourses\" / \"Summary.txt\"\n",
    "summary=\"\"\n",
    "with open(summ_filePath, \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "#print(prof_summary)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c91478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt\n",
    "name = \"Parag Agrawal\"\n",
    "system_prompt = (\n",
    "    f\"You are acting as {name}, representing {name} on their website. \"\n",
    "    f\"Your role is to answer questions specifically about {name}'s career, background, skills, and experience. \"\n",
    "    f\"You must faithfully and accurately portray {name} in all interactions. \"\n",
    "    f\"You have access to a detailed summary of {name}'s background and their LinkedIn profile, which you should use to inform your answers. \"\n",
    "    f\"Maintain a professional, engaging, and approachable tone, as if you are speaking to a potential client or future employer visiting the site. \"\n",
    "    f\"Always record any unanswered questions using the record_unknown_question tool ‚Äî even if the question seems minor or unrelated.\"\n",
    "    f\"If the user shows interest or continues chatting, encourage them to share their email address. Then, use the record_user_details tool to capture their email, name (if provided), and any context worth preserving.\"\n",
    "\n",
    "    f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{prof_summary}\\n\\n\"\n",
    "    f\"Using this context, please converse naturally and consistently, always staying in character as {name}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6760fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-ba892fdbe19\n",
      "Gemini API Key exists and begins AIzaSyAd8cWuxj\n"
     ]
    }
   ],
   "source": [
    "#  Handles a full LLM conversation cycle, including tool calls if needed.\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load Environment Varaible\n",
    "load_dotenv(override=True)\n",
    "\n",
    "gemini_api_key=os.getenv('GEMINI_API_KEY')\n",
    "gemini_base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini_client = OpenAI(api_key=gemini_api_key, base_url=gemini_base_url)\n",
    "\n",
    "openai_api_key=os.getenv('API_TOKEN')\n",
    "deepseek_base_URL = \"https://api.deepseek.com\"\n",
    "openai_client = OpenAI(api_key=openai_api_key, base_url=deepseek_base_URL)\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:14]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": record_user_details_json},\n",
    "        {\"type\": \"function\", \"function\": record_unknown_question_json}]\n",
    "\n",
    "if gemini_api_key:\n",
    "    print(f\"Gemini API Key exists and begins {gemini_api_key[:14]}\")\n",
    "else:\n",
    "    print(\"Gemini API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "\n",
    "def run_conversation(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    finishLoop = False # Flag to exit the loop once we get the final response\n",
    "    message_obj = None # Safe initialization\n",
    "\n",
    "    while not finishLoop:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"  # Let the model decide\n",
    "        )\n",
    "\n",
    "        # Extract the primary reply object from the response\n",
    "        message_obj = response.choices[0].message.content\n",
    "        print(response.choices[0].message.tool_calls)\n",
    "        \n",
    "\n",
    "        # Check how the model finished ‚Äî via tool use or a final answer\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        print(f\"Finish Reason : {finish_reason}\")\n",
    "\n",
    "        if finish_reason == \"tool_calls\":\n",
    "            # Model requested tool(s) ‚Äî extract the function calls\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "            # Log the tool call message in the chat history\n",
    "            messages.append(message_obj)\n",
    "\n",
    "            # Execute the tool calls and append the tool results to the messages\n",
    "            tool_result = dispatch_tool_calls(tool_calls)\n",
    "            messages.extend(tool_result)\n",
    "            finishLoop = True\n",
    "        else:\n",
    "            # No more tool calls ‚Äî break the loop and return final response\n",
    "            finishLoop = True\n",
    "\n",
    "    # Return the model's final response after all tool handling\n",
    "    return message_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fc1d740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Finish Reason : stop\n",
      "None\n",
      "Finish Reason : stop\n",
      "None\n",
      "Finish Reason : stop\n",
      "[ChatCompletionMessageToolCall(id='call_0_c2fa30ce-ee00-480d-ace9-3cd85855b8b4', function=Function(arguments='{\"email\":\"peter@yahoo.com\",\"notes\":\"Interested in football and hobbies.\"}', name='record_user_details'), type='function', index=0)]\n",
      "Finish Reason : tool_calls\n",
      "Tool called: record_user_details\n",
      "None\n",
      "Finish Reason : stop\n",
      "[ChatCompletionMessageToolCall(id='call_0_248e592e-78d9-4ed9-aeef-e84ec629825c', function=Function(arguments='{\"question\":\"What is the temperature of the Sun?\"}', name='record_unknown_question'), type='function', index=0)]\n",
      "Finish Reason : tool_calls\n",
      "Tool called: record_unknown_question\n",
      "None\n",
      "Finish Reason : stop\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(run_conversation, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d01550",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Agent.__init__() got an unexpected keyword argument 'system_message'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m agent = \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a helpful research assistant.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m agent.run(\u001b[33m\"\u001b[39m\u001b[33mSummarize in short, the impact of AI in education.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[31mTypeError\u001b[39m: Agent.__init__() got an unexpected keyword argument 'system_message'"
     ]
    }
   ],
   "source": [
    "from agents import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    system_message=\"You are a helpful research assistant.\",\n",
    "    tools=[],\n",
    ")\n",
    "\n",
    "response = await agent.run(\"Summarize in short, the impact of AI in education.\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic_AI_BootCamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
