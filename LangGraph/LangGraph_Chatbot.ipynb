{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4d2ec1",
   "metadata": {},
   "source": [
    "## LangGraph Chatbot Hands On without LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d97215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/b21vyw1s0v727y0fc2phllm00000gn/T/ipykernel_50129/3794000342.py:154: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(height=200, label=\"Conversation\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7885\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7885/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Initial State ===\n",
      "Messages:\n",
      "  0: [Human] Hello\n",
      "=================\n",
      "\n",
      "\n",
      "=== Final State ===\n",
      "Messages:\n",
      "  0: [Human] Hello\n",
      "  1: [AI] ðŸ—£ You said: Hello\n",
      "=================\n",
      "\n",
      "\n",
      "=== Initial State ===\n",
      "Messages:\n",
      "  0: [Human] Hello\n",
      "  1: [AI] ðŸ—£ You said: Hello\n",
      "  2: [Human] hello, what is the main fact\n",
      "=================\n",
      "\n",
      "\n",
      "=== Final State ===\n",
      "Messages:\n",
      "  0: [Human] Hello\n",
      "  1: [AI] ðŸ—£ You said: Hello\n",
      "  2: [Human] hello, what is the main fact\n",
      "  3: [AI] ðŸ¤¯ Fun Fact: Penguins propose with pebbles.\n",
      "=================\n",
      "\n",
      "\n",
      "=== Initial State ===\n",
      "Messages:\n",
      "  0: [Human] Hello\n",
      "  1: [AI] ðŸ—£ You said: Hello\n",
      "  2: [Human] hello, what is the main fact\n",
      "  3: [AI] ðŸ¤¯ Fun Fact: Penguins propose with pebbles.\n",
      "  4: [Human] tell me another fact\n",
      "=================\n",
      "\n",
      "\n",
      "=== Final State ===\n",
      "Messages:\n",
      "  0: [Human] Hello\n",
      "  1: [AI] ðŸ—£ You said: Hello\n",
      "  2: [Human] hello, what is the main fact\n",
      "  3: [AI] ðŸ¤¯ Fun Fact: Penguins propose with pebbles.\n",
      "  4: [Human] tell me another fact\n",
      "  5: [AI] ðŸ¤¯ Fun Fact: Octopuses have three hearts.\n",
      "=================\n",
      "\n",
      "\n",
      "=== Initial State ===\n",
      "Messages:\n",
      "  0: [Human] Hello\n",
      "  1: [AI] ðŸ—£ You said: Hello\n",
      "  2: [Human] hello, what is the main fact\n",
      "  3: [AI] ðŸ¤¯ Fun Fact: Penguins propose with pebbles.\n",
      "  4: [Human] tell me another fact\n",
      "  5: [AI] ðŸ¤¯ Fun Fact: Octopuses have three hearts.\n",
      "  6: [Human] Bye\n",
      "=================\n",
      "\n",
      "\n",
      "=== Final State ===\n",
      "Messages:\n",
      "  0: [Human] Hello\n",
      "  1: [AI] ðŸ—£ You said: Hello\n",
      "  2: [Human] hello, what is the main fact\n",
      "  3: [AI] ðŸ¤¯ Fun Fact: Penguins propose with pebbles.\n",
      "  4: [Human] tell me another fact\n",
      "  5: [AI] ðŸ¤¯ Fun Fact: Octopuses have three hearts.\n",
      "  6: [Human] Bye\n",
      "  7: [AI] ðŸ‘‹ Goodbye! Come chat again.\n",
      "=================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, List\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "import operator\n",
    "import gradio as gr\n",
    "import random\n",
    "from typing import TypedDict\n",
    "\n",
    "# Define the State properly using TypedDict\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "\n",
    "# Create Nodes that return proper state updates\n",
    "def greeter(state: State):\n",
    "    \"\"\"Welcome message - only sent once per conversation\"\"\"\n",
    "    if not any(isinstance(msg, AIMessage) for msg in state[\"messages\"]):\n",
    "        return {\"messages\": [AIMessage(content=\"ðŸ‘‹ Hello! I'm your chatbot.\")]}\n",
    "    return {\"messages\": []}\n",
    "\n",
    "\n",
    "def echo_user(state: State):\n",
    "    \"\"\"Echo user input\"\"\"\n",
    "    # Get the last user message\n",
    "    user_messages = [msg for msg in state[\"messages\"] if isinstance(msg, HumanMessage)]\n",
    "    if user_messages:\n",
    "        last_user_msg = user_messages[-1]\n",
    "        return {\"messages\": [AIMessage(content=f\"ðŸ—£ You said: {last_user_msg.content}\")]}\n",
    "    return {\"messages\": []}\n",
    "\n",
    "\n",
    "def random_fact(state: State):\n",
    "    \"\"\"Provide a random fact\"\"\"\n",
    "    facts = [\n",
    "        \"Bananas are berries, but strawberries aren't.\",\n",
    "        \"Octopuses have three hearts.\",\n",
    "        \"Penguins propose with pebbles.\"\n",
    "    ]\n",
    "    return {\"messages\": [AIMessage(content=f\"ðŸ¤¯ Fun Fact: {random.choice(facts)}\")]}\n",
    "\n",
    "\n",
    "def farewell(state: State):\n",
    "    \"\"\"Say goodbye\"\"\"\n",
    "    return {\"messages\": [AIMessage(content=\"ðŸ‘‹ Goodbye! Come chat again.\")]}\n",
    "\n",
    "\n",
    "# Router function for conditional edges\n",
    "def router(state: State):\n",
    "    \"\"\"Determine which node to execute based on user input\"\"\"\n",
    "\n",
    "    # Get the last user message\n",
    "    user_messages = [msg for msg in state[\"messages\"] if isinstance(msg, HumanMessage)]\n",
    "    if not user_messages:\n",
    "        return \"greeter\"\n",
    "\n",
    "    last_user_msg = user_messages[-1]\n",
    "    user_input = last_user_msg.content.lower()\n",
    "\n",
    "    if \"fact\" in user_input:\n",
    "        return \"fact\"\n",
    "    elif any(word in user_input for word in [\"bye\", \"goodbye\", \"exit\", \"quit\"]):\n",
    "        return \"farewell\"\n",
    "    else:\n",
    "        return \"echo\"\n",
    "\n",
    "\n",
    "# Build Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"greeter\", greeter)\n",
    "builder.add_node(\"echo\", echo_user)\n",
    "builder.add_node(\"fact\", random_fact)\n",
    "builder.add_node(\"farewell\", farewell)\n",
    "\n",
    "# Set up conditional routing\n",
    "builder.add_conditional_edges(\n",
    "    START, \n",
    "    router, \n",
    "    [\"greeter\", \"echo\", \"fact\", \"farewell\"]\n",
    ")\n",
    "\n",
    "# Add edges from nodes to END\n",
    "builder.add_edge(\"greeter\", END)\n",
    "builder.add_edge(\"echo\", END)\n",
    "builder.add_edge(\"fact\", END)\n",
    "builder.add_edge(\"farewell\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile()\n",
    "\n",
    "# Helper function to print state in a readable format\n",
    "def print_state(state, title=\"State\"):\n",
    "    \"\"\"Print the state in a readable format\"\"\"\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    if \"messages\" in state:\n",
    "        print(\"Messages:\")\n",
    "        for i, msg in enumerate(state[\"messages\"]):\n",
    "            msg_type = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "            print(f\"  {i}: [{msg_type}] {msg.content}\")\n",
    "    else:\n",
    "        print(\"No messages in state\")\n",
    "    print(\"=================\\n\")\n",
    "\n",
    "\n",
    "# Create Gradio Chat Interface\n",
    "def chat_fn(message, chat_history):\n",
    "    \"\"\"Handle chat interactions\"\"\"\n",
    "    # Convert chat history to messages\n",
    "    messages = []\n",
    "    for user_msg, bot_msg in chat_history:\n",
    "        messages.append(HumanMessage(content=user_msg))\n",
    "        messages.append(AIMessage(content=bot_msg))\n",
    "\n",
    "    # Add the current user message\n",
    "    messages.append(HumanMessage(content=message))\n",
    "\n",
    "    # Create initial state\n",
    "    initial_state = {\"messages\": messages}\n",
    "\n",
    "    # Print initial state\n",
    "    print_state(initial_state, \"Initial State\")\n",
    "\n",
    "    try:\n",
    "        # Execute the graph\n",
    "        result = graph.invoke(initial_state)\n",
    "\n",
    "        # Print final state\n",
    "        print_state(result, \"Final State\")\n",
    "\n",
    "        # Extract the new AI responses (only the ones added in this invocation)\n",
    "        new_ai_messages = [\n",
    "            msg for msg in result[\"messages\"] \n",
    "            if isinstance(msg, AIMessage) and msg not in messages\n",
    "        ]\n",
    "\n",
    "        # Get the latest AI response\n",
    "        latest_response = new_ai_messages[-1].content if new_ai_messages else \"I didn't understand that.\"\n",
    "\n",
    "        # Append to chat history\n",
    "        chat_history.append((message, latest_response))\n",
    "        return \"\", chat_history\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        chat_history.append((message, \"Sorry, I encountered an error. Please try again.\"))\n",
    "        return \"\", chat_history\n",
    "\n",
    "\n",
    "# Create the interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ðŸ¤– LangGraph Chatbot Demo\")\n",
    "\n",
    "    chatbot = gr.Chatbot(height=200, label=\"Conversation\")\n",
    "    msg = gr.Textbox(label=\"Your Message\", placeholder=\"Type your message here...\")\n",
    "    clear = gr.Button(\"Clear Chat\")\n",
    "\n",
    "    msg.submit(chat_fn, [msg, chatbot], [msg, chatbot])\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic_AI_BootCamp (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
